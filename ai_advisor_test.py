import json
import openai
import os
import sys
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv
print("âœ… LOADED services/ai_advisor.py FROM:", __file__)


# ==========================================
# ğŸ› ï¸ ä¿®å¤ 1: å¼ºåˆ¶ Windows è¾“å‡º UTF-8 (è§£å†³æŠ¥é”™æ ¸å¿ƒ)
# ==========================================
# è¿™ä¸€è¡Œæ˜¯è§£å†³ 'ascii' codec can't encode... çš„å…³é”®
try:
    sys.stdout.reconfigure(encoding="utf-8")
except Exception:
    pass


# 2) å¦‚æœ api_key ç¼ºå¤±ï¼Œç›´æ¥ raiseï¼ˆä¸è¦è®© client å¸¦ None è¿è¡Œï¼‰
api_key = os.getenv("DEEPSEEK_API_KEY")
if not api_key:
    raise RuntimeError(f"Missing DEEPSEEK_API_KEY, please check {env_path}")

client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


# ==========================================
# ğŸ“‚ é…ç½®è·¯å¾„ä¸ Key (ä¿ç•™ä½ æŒ‡å®šçš„ç»å¯¹è·¯å¾„)
# ==========================================
# 1. ä½ çš„é¡¹ç›®æ ¹ç›®å½•
project_root = Path(r"C:\Users\sumik\Desktop\AI_Project")
env_path = project_root / ".env"

# 2. åŠ è½½ç¯å¢ƒå˜é‡
print(f"ğŸ” [AI Advisor] æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶: {env_path}")
load_dotenv(dotenv_path=env_path, override=True)

# 3. è·å– API Key
api_key = os.getenv("DEEPSEEK_API_KEY")

# 4. æ£€æŸ¥ Key
if not api_key:
    # å°è¯•æ‰¾ä¸€ä¸‹ .env.txt è¿™ç§å¸¸è§é”™è¯¯
    if (project_root / ".env.txt").exists():
        print("âš ï¸ è­¦å‘Š: å‘ç°äº† .env.txtï¼Œè¯·é‡å‘½åä¸º .env")
    print(f"âŒ [AI Advisor] é”™è¯¯: æœªæ‰¾åˆ° API Keyï¼Œè¯·æ£€æŸ¥ {env_path}")
    # å¯ä»¥åœ¨è¿™é‡Œä¸´æ—¶å¡«å…¥ Key è¿›è¡Œæµ‹è¯• (ä½†ä¸å»ºè®®æäº¤)
    # api_key = "sk-..." 
else:
    print(f"âœ… [AI Advisor] API Key åŠ è½½æˆåŠŸ")

# 5. åˆå§‹åŒ– OpenAI Client
client = OpenAI(
    api_key=api_key, 
    base_url="https://api.deepseek.com" 
)

# ==========================================
# ğŸ§¹ å·¥å…·å‡½æ•°
# ==========================================
def clean_ai_response(raw_response):
    """æ¸…æ´— AI è¿”å›çš„ Markdown æ ¼å¼ï¼Œæå–çº¯ JSON"""
    if not raw_response:
        return ""
    clean_text = raw_response.replace("```json", "").replace("```", "")
    return clean_text.strip()

# ==========================================
# ğŸ§  æ ¸å¿ƒåŠŸèƒ½ 1: ç®€å†è¯Šæ–­ (å«è¯„åˆ†ç†ç”±)
# ==========================================
def analyze_resume(resume_text):
    """
    åˆ†æç®€å†ï¼Œè¿”å›åŒ…å« score_rationale çš„å®Œæ•´ JSON
    """
    print("ğŸš€ [AI Advisor] æ­£åœ¨è°ƒç”¨ DeepSeek è¿›è¡Œæ·±åº¦è¯Šæ–­...")
    
    # è¿™ä¸ª Prompt ä¿ç•™äº†ä½ è¦æ±‚çš„æ‰€æœ‰å­—æ®µ
    system_prompt = """
    ä½ æ˜¯ä¸€ä½èµ„æ·±æŠ€æœ¯é¢è¯•å®˜ã€‚è¯·åˆ†æç®€å†å¹¶ä¸¥æ ¼è¾“å‡ºçº¯ JSON æ ¼å¼ã€‚
    
    ã€æ ¸å¿ƒè¦æ±‚ã€‘
    1. "score_rationale": å¿…é¡»ç”¨ä¸€å¥è¯è§£é‡Šä¸ºä»€ä¹ˆç»™è¿™ä¸ªåˆ†æ•°ï¼ˆè¿™æ˜¯æ ¸å¿ƒåŠŸèƒ½ï¼Œå¿…å¡«ï¼‰ã€‚
    2. "suggestions": æå»ºè®®æ—¶ï¼Œå¿…é¡»åœ¨ "evidence" å­—æ®µæŒ‡å‡ºç®€å†åŸæ–‡çš„é—®é¢˜ã€‚

    è¿”å›æ ¼å¼ï¼ˆçº¯JSONï¼‰ï¼š
    {
        "score": (0-100æ•´æ•°),
        "score_rationale": "è¯„åˆ†ä¾æ®",
        "summary": "ç»¼åˆç‚¹è¯„",
        "pros": ["äº®ç‚¹1", "äº®ç‚¹2"],
        "cons": ["ä¸è¶³1", "ä¸è¶³2"],
        "suggestions": [
            {
                "advice": "ä¿®æ”¹å»ºè®®",
                "evidence": "ç®€å†åŸæ–‡å¼•ç”¨"
            }
        ],
        "matched_jobs": ["æ¨èå²—ä½1", "æ¨èå²—ä½2"]
    }
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¿™æ˜¯æˆ‘çš„ç®€å†å†…å®¹ï¼š\n{resume_text}"}
            ],
            temperature=0.2,
            response_format={ "type": "json_object" } 
        )
        
        raw_result = response.choices[0].message.content
        clean_result = clean_ai_response(raw_result)
        
        # è§£æ JSON
        return json.loads(clean_result)
            
    except Exception as e:
        # ä½¿ç”¨ repr() é˜²æ­¢ä¸­æ–‡æŠ¥é”™ç‚¸æ¯æ•´ä¸ªç¨‹åº
        print(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {repr(e)}")
        return None

# ==========================================
# âœï¸ æ ¸å¿ƒåŠŸèƒ½ 2: ç®€å†ç”Ÿæˆ (ä½ çš„æ–°åŠŸèƒ½)
# ==========================================
def generate_resume_markdown(prompt: str, temperature: float = 0.6) -> str:
    """
    ç”Ÿæˆ/ä¼˜åŒ–ç®€å†å†…å®¹ï¼ˆè¿”å› Markdown æ–‡æœ¬ï¼‰
    """
    print("âœï¸ [AI Advisor] æ­£åœ¨è°ƒç”¨ DeepSeek ç”Ÿæˆä¼˜åŒ–ç‰ˆç®€å†...")
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸¥è°¨çš„ç®€å†ä¼˜åŒ–ä¸“å®¶ï¼Œè¯·ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„ç®€å†å†…å®¹ï¼Œä¸è¦åŒ…å« ```markdown æ ‡è®°ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {repr(e)}")
        return f"AI ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}"

def get_deepseek_client():
    api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("DEEPSEEK_KEY")
    if not api_key:
        raise RuntimeError("Missing DEEPSEEK_API_KEY in env.")
    return OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
print("âœ… ai_advisor loaded, has get_deepseek_client:", "get_deepseek_client" in globals())

# æ–°å¢ï¼šèŒä¸šä½“éªŒæ€»ç»“Markdownç”Ÿæˆå‡½æ•°ï¼ˆå’Œä½ çš„main.pyé€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
def generate_simulation_summary_markdown(role_name: str, final_score: int, hp: int, logs: list):
    """
    ç”ŸæˆèŒä¸šä½“éªŒæ€»ç»“çš„Markdownå†…å®¹
    :param role_name: èŒä¸šåç§°
    :param final_score: æœ€ç»ˆå¾—åˆ†
    :param hp: å‰©ä½™ç”Ÿå‘½å€¼
    :param logs: ç²¾ç®€åçš„ä½“éªŒæ—¥å¿—åˆ—è¡¨
    :return: å¤§æ¨¡å‹ç”Ÿæˆçš„Markdownæ ¼å¼æ€»ç»“å­—ç¬¦ä¸²
    """
    # æ‹¼æ¥æ—¥å¿—ä¸ºpromptå¯ç”¨çš„æ–‡æœ¬æ ¼å¼ï¼ˆä¿ç•™ä½ çš„æˆªæ–­/ç²¾ç®€é€»è¾‘ï¼‰
    logs_text = ""
    for idx, log in enumerate(logs, 1):
        logs_text += f"{idx}. åœºæ™¯ï¼š{log['scene']} | é€‰æ‹©ï¼š{log['choice']} | åé¦ˆï¼š{log['feedback']} | åˆ†æ•°å˜åŒ–ï¼š{log['score_change']}\n"
    
    # ä½ åŸæœ‰çš„promptï¼Œä¸€å­—æœªæ”¹ï¼Œå®Œå…¨ä¿ç•™
    prompt = f"""
    ä½ æ˜¯ä¸¥è°¨çš„èŒä¸šè§„åˆ’é¡¾é—®ã€‚ç”¨æˆ·åˆšå®Œæˆã€è™šæ‹ŸèŒä¸šä½“éªŒã€‘ã€‚
    ã€èŒä¸šã€‘{role_name}
    ã€æœ€ç»ˆå¾—åˆ†ã€‘{final_score}
    ã€å‰©ä½™ç”Ÿå‘½å€¼ã€‘{hp}
    ã€ä½“éªŒæ—¥å¿—ã€‘
    {logs_text}
    è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½èŒä¸šä½“éªŒæ€»ç»“æŠ¥å‘Šï¼Œè¦æ±‚ï¼š
    1. åŒ…å«èŒä¸šåŒ¹é…åº¦åˆ†æï¼ˆç»“åˆå¾—åˆ†å’Œè¡Œä¸ºï¼‰
    2. åˆ†æç”¨æˆ·çš„èŒä¸šä¼˜åŠ¿å’ŒçŸ­æ¿
    3. ç»™å‡º3æ¡å…·ä½“çš„èŒä¸šæå‡å»ºè®®
    4. æœ€åç”¨ä¸€å¥è¯ç»™å‡ºæ ¸å¿ƒç»“è®º
    5. å…¨ç¨‹ä½¿ç”¨markdownæ ¼å¼ï¼Œåˆ†æ ‡é¢˜å±‚çº§ï¼Œè¯­è¨€ç®€æ´ä¸“ä¸š
    """
    
    # è°ƒç”¨DeepSeekå¤§æ¨¡å‹ï¼ˆå¤ç”¨ä½ é¡¹ç›®ç°æœ‰é…ç½®ï¼Œæ¨¡å‹å/å‚æ•°ä¸å˜ï¼‰
    response = openai.ChatCompletion.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt.strip()}],
        temperature=0.7,
        max_tokens=1024
    )
    # æå–å¹¶è¿”å›ç”Ÿæˆçš„Markdownå†…å®¹
    md_content = response.choices[0].message["content"].strip()
    return md_content


# åœ¨ ai_advisor.py æ–‡ä»¶æœ«å°¾
__all__ = [
    "generate_simulation_summary_markdown"
]